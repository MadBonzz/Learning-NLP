{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import string\n",
    "from tensorflow import keras\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import PorterStemmer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.read_csv('financial_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Sentiment\n",
       "0  The GeoSolutions technology will leverage Bene...  positive\n",
       "1  $ESI on lows, down $1.50 to $2.50 BK a real po...  negative\n",
       "2  For the last quarter of 2010 , Componenta 's n...  positive\n",
       "3  According to the Finnish-Russian Chamber of Co...   neutral\n",
       "4  The Swedish buyout firm has sold its remaining...   neutral"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence     0\n",
       "Sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "neutral     3130\n",
       "positive    1852\n",
       "negative     860\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puncs = string.punctuation\n",
    "puncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(text):\n",
    "    return text.translate(str.maketrans(' ', ' ', puncs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentence'] = df['Sentence'].apply(remove_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    cleaned_text = []\n",
    "    text = text.split(' ')\n",
    "    for word in text:\n",
    "        if word in stopwords.words('english'):\n",
    "            cleaned_text.append(\"\")\n",
    "        else:\n",
    "            cleaned_text.append(word)\n",
    "    cleaned_str = cleaned_text[:]\n",
    "    return ' '.join(cleaned_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentence'] = df['Sentence'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Sentence'].apply(lambda x: len(x.split()) >= 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(text):\n",
    "    return \" \".join([ps.stem(word) for word in text.split(' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentence'] = df['Sentence'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Sentence']\n",
    "Y = df['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_test = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = Word2Vec(vector_size=100, min_count=2, workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = x_train.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_corpus = []\n",
    "\n",
    "for sentence in corpus:\n",
    "    input_corpus.append(sentence.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.build_vocab(input_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(267378, 485975)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.train(input_corpus, total_examples=wv.corpus_count, epochs=wv.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_vectorizer(doc):\n",
    "    doc = [word for word in doc.split() if word in wv.wv.index_to_key]\n",
    "    return np.mean(wv.wv[doc], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.61473244e-01,  2.12832719e-01,  1.99001968e-01,  2.14132279e-01,\n",
       "       -9.33123529e-02, -4.96508837e-01,  2.01662242e-01,  6.66209638e-01,\n",
       "       -2.43261769e-01, -1.54276326e-01,  1.09487474e-01, -2.93196887e-01,\n",
       "       -1.46771267e-01,  1.51218072e-01,  7.72585720e-02, -2.60082800e-02,\n",
       "        1.32303506e-01, -2.12638348e-01, -1.48452803e-01, -6.63034797e-01,\n",
       "        3.30885231e-01,  2.51840413e-01,  2.66760081e-01, -4.36811766e-04,\n",
       "       -2.21049994e-01,  3.87863070e-02, -1.41406760e-01, -9.32805985e-02,\n",
       "       -4.54795212e-01, -9.59474444e-02,  2.65165508e-01, -4.63950541e-03,\n",
       "        2.42000937e-01, -2.20693558e-01, -8.86337161e-02,  2.63509721e-01,\n",
       "        3.91096890e-01, -3.30680311e-01, -1.09677613e-01, -3.94177377e-01,\n",
       "       -1.41956642e-01, -4.47916165e-02, -2.96374500e-01,  7.34105706e-02,\n",
       "        3.55456680e-01, -1.09327182e-01, -3.94090205e-01,  2.26625964e-01,\n",
       "        7.18851537e-02,  1.91524714e-01, -4.52317782e-02,  7.97542036e-02,\n",
       "       -2.01431870e-01, -6.68301806e-02,  1.53068185e-01,  1.32838041e-01,\n",
       "        2.13106066e-01,  3.86048853e-03, -8.00912306e-02,  7.70231113e-02,\n",
       "       -9.70804468e-02,  1.75773278e-01, -2.19017819e-01, -1.69738382e-01,\n",
       "       -1.54604927e-01,  2.50658631e-01, -1.33592978e-01,  3.01946223e-01,\n",
       "       -2.62564331e-01,  3.45482886e-01,  4.56101783e-02,  2.17107370e-01,\n",
       "        1.25774130e-01, -2.52826184e-01,  2.88545549e-01, -6.41331915e-03,\n",
       "        3.17114502e-01, -1.50551558e-01, -2.76016146e-01,  8.08171257e-02,\n",
       "       -2.80635990e-02,  1.25642151e-01, -4.66750078e-02,  4.01046515e-01,\n",
       "       -2.95652330e-01,  6.59885779e-02,  6.32136688e-03,  3.08363378e-01,\n",
       "        2.22216725e-01,  1.30834833e-01,  2.23323271e-01, -2.94689573e-02,\n",
       "        4.65662740e-02,  1.85429260e-01,  6.78658724e-01,  3.87424797e-01,\n",
       "       -1.13385417e-01, -4.00379092e-01,  1.40420571e-01,  8.60844180e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_vectorizer('the geosolut technolog   leverag benefon   gp solut   provid locat base search technolog    commun platform  locat relev multimedia content     new   power commerci model ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.DataFrame(x_train)\n",
    "x_test = pd.DataFrame(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'insur old mutual pick standard bank hemphil  new ceo'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train['Sentence'].values[4449]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4531 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4531/4531 [00:02<00:00, 2201.82it/s]\n"
     ]
    }
   ],
   "source": [
    "input_x = []\n",
    "for doc in tqdm(x_train['Sentence'].values):\n",
    "    input_x.append(document_vectorizer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1133/1133 [00:00<00:00, 2000.98it/s]\n"
     ]
    }
   ],
   "source": [
    "test_x = []\n",
    "for doc in tqdm(x_test['Sentence'].values):\n",
    "    test_x.append(document_vectorizer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.DataFrame(input_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pd.DataFrame(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.065180</td>\n",
       "      <td>0.047393</td>\n",
       "      <td>-0.278572</td>\n",
       "      <td>0.054961</td>\n",
       "      <td>-0.031771</td>\n",
       "      <td>-0.824347</td>\n",
       "      <td>0.158188</td>\n",
       "      <td>1.106758</td>\n",
       "      <td>-0.243654</td>\n",
       "      <td>0.316453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.708754</td>\n",
       "      <td>0.046114</td>\n",
       "      <td>0.278076</td>\n",
       "      <td>-0.248840</td>\n",
       "      <td>1.710252</td>\n",
       "      <td>0.023575</td>\n",
       "      <td>-0.473314</td>\n",
       "      <td>-0.711494</td>\n",
       "      <td>0.031659</td>\n",
       "      <td>0.250035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.132199</td>\n",
       "      <td>0.168852</td>\n",
       "      <td>0.149055</td>\n",
       "      <td>0.171227</td>\n",
       "      <td>-0.076316</td>\n",
       "      <td>-0.445166</td>\n",
       "      <td>0.171261</td>\n",
       "      <td>0.592303</td>\n",
       "      <td>-0.199368</td>\n",
       "      <td>-0.109264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210108</td>\n",
       "      <td>-0.020960</td>\n",
       "      <td>0.055184</td>\n",
       "      <td>0.141529</td>\n",
       "      <td>0.620137</td>\n",
       "      <td>0.313458</td>\n",
       "      <td>-0.108117</td>\n",
       "      <td>-0.356073</td>\n",
       "      <td>0.116703</td>\n",
       "      <td>0.082185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.131432</td>\n",
       "      <td>0.175389</td>\n",
       "      <td>0.157716</td>\n",
       "      <td>0.192019</td>\n",
       "      <td>-0.082181</td>\n",
       "      <td>-0.440687</td>\n",
       "      <td>0.171520</td>\n",
       "      <td>0.599991</td>\n",
       "      <td>-0.208943</td>\n",
       "      <td>-0.122566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221674</td>\n",
       "      <td>-0.019684</td>\n",
       "      <td>0.047049</td>\n",
       "      <td>0.148593</td>\n",
       "      <td>0.641646</td>\n",
       "      <td>0.335417</td>\n",
       "      <td>-0.120881</td>\n",
       "      <td>-0.367762</td>\n",
       "      <td>0.119429</td>\n",
       "      <td>0.084265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.119690</td>\n",
       "      <td>0.164854</td>\n",
       "      <td>0.110994</td>\n",
       "      <td>0.181838</td>\n",
       "      <td>-0.080271</td>\n",
       "      <td>-0.514079</td>\n",
       "      <td>0.179196</td>\n",
       "      <td>0.695668</td>\n",
       "      <td>-0.214826</td>\n",
       "      <td>-0.070413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288664</td>\n",
       "      <td>-0.012950</td>\n",
       "      <td>0.080446</td>\n",
       "      <td>0.104609</td>\n",
       "      <td>0.798205</td>\n",
       "      <td>0.308668</td>\n",
       "      <td>-0.170043</td>\n",
       "      <td>-0.426662</td>\n",
       "      <td>0.111443</td>\n",
       "      <td>0.114751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.080714</td>\n",
       "      <td>0.111533</td>\n",
       "      <td>0.089116</td>\n",
       "      <td>0.106594</td>\n",
       "      <td>-0.050041</td>\n",
       "      <td>-0.281815</td>\n",
       "      <td>0.105255</td>\n",
       "      <td>0.377127</td>\n",
       "      <td>-0.121493</td>\n",
       "      <td>-0.070072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130755</td>\n",
       "      <td>-0.011297</td>\n",
       "      <td>0.035960</td>\n",
       "      <td>0.088551</td>\n",
       "      <td>0.397768</td>\n",
       "      <td>0.198146</td>\n",
       "      <td>-0.071384</td>\n",
       "      <td>-0.224143</td>\n",
       "      <td>0.072020</td>\n",
       "      <td>0.052232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4526</th>\n",
       "      <td>-0.120349</td>\n",
       "      <td>0.159164</td>\n",
       "      <td>0.138883</td>\n",
       "      <td>0.154837</td>\n",
       "      <td>-0.070032</td>\n",
       "      <td>-0.401689</td>\n",
       "      <td>0.156226</td>\n",
       "      <td>0.539385</td>\n",
       "      <td>-0.186336</td>\n",
       "      <td>-0.106543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185919</td>\n",
       "      <td>-0.015625</td>\n",
       "      <td>0.049283</td>\n",
       "      <td>0.126782</td>\n",
       "      <td>0.559375</td>\n",
       "      <td>0.287423</td>\n",
       "      <td>-0.097047</td>\n",
       "      <td>-0.319445</td>\n",
       "      <td>0.107496</td>\n",
       "      <td>0.073171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4527</th>\n",
       "      <td>-0.161192</td>\n",
       "      <td>0.219307</td>\n",
       "      <td>0.210620</td>\n",
       "      <td>0.255361</td>\n",
       "      <td>-0.115812</td>\n",
       "      <td>-0.651596</td>\n",
       "      <td>0.238353</td>\n",
       "      <td>0.881353</td>\n",
       "      <td>-0.297987</td>\n",
       "      <td>-0.166253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330815</td>\n",
       "      <td>-0.036700</td>\n",
       "      <td>0.091299</td>\n",
       "      <td>0.171524</td>\n",
       "      <td>0.953727</td>\n",
       "      <td>0.444943</td>\n",
       "      <td>-0.180488</td>\n",
       "      <td>-0.544302</td>\n",
       "      <td>0.170642</td>\n",
       "      <td>0.119135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4528</th>\n",
       "      <td>-0.072521</td>\n",
       "      <td>0.145689</td>\n",
       "      <td>0.052844</td>\n",
       "      <td>0.181196</td>\n",
       "      <td>-0.081720</td>\n",
       "      <td>-0.507918</td>\n",
       "      <td>0.162997</td>\n",
       "      <td>0.685408</td>\n",
       "      <td>-0.199122</td>\n",
       "      <td>-0.019366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.335518</td>\n",
       "      <td>0.006020</td>\n",
       "      <td>0.098136</td>\n",
       "      <td>0.082026</td>\n",
       "      <td>0.850471</td>\n",
       "      <td>0.266974</td>\n",
       "      <td>-0.209178</td>\n",
       "      <td>-0.440364</td>\n",
       "      <td>0.095453</td>\n",
       "      <td>0.131223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4529</th>\n",
       "      <td>-0.128059</td>\n",
       "      <td>0.181737</td>\n",
       "      <td>0.148587</td>\n",
       "      <td>0.194918</td>\n",
       "      <td>-0.089350</td>\n",
       "      <td>-0.509447</td>\n",
       "      <td>0.191452</td>\n",
       "      <td>0.702318</td>\n",
       "      <td>-0.231405</td>\n",
       "      <td>-0.102552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293210</td>\n",
       "      <td>-0.019773</td>\n",
       "      <td>0.068850</td>\n",
       "      <td>0.124524</td>\n",
       "      <td>0.795496</td>\n",
       "      <td>0.349724</td>\n",
       "      <td>-0.159801</td>\n",
       "      <td>-0.435084</td>\n",
       "      <td>0.127403</td>\n",
       "      <td>0.108350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4530</th>\n",
       "      <td>-0.107899</td>\n",
       "      <td>0.177885</td>\n",
       "      <td>0.127513</td>\n",
       "      <td>0.204135</td>\n",
       "      <td>-0.095469</td>\n",
       "      <td>-0.553412</td>\n",
       "      <td>0.197229</td>\n",
       "      <td>0.750886</td>\n",
       "      <td>-0.235143</td>\n",
       "      <td>-0.084067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316175</td>\n",
       "      <td>-0.015192</td>\n",
       "      <td>0.090131</td>\n",
       "      <td>0.127776</td>\n",
       "      <td>0.865403</td>\n",
       "      <td>0.341015</td>\n",
       "      <td>-0.190215</td>\n",
       "      <td>-0.469826</td>\n",
       "      <td>0.123497</td>\n",
       "      <td>0.117477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4531 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.065180  0.047393 -0.278572  0.054961 -0.031771 -0.824347  0.158188   \n",
       "1    -0.132199  0.168852  0.149055  0.171227 -0.076316 -0.445166  0.171261   \n",
       "2    -0.131432  0.175389  0.157716  0.192019 -0.082181 -0.440687  0.171520   \n",
       "3    -0.119690  0.164854  0.110994  0.181838 -0.080271 -0.514079  0.179196   \n",
       "4    -0.080714  0.111533  0.089116  0.106594 -0.050041 -0.281815  0.105255   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4526 -0.120349  0.159164  0.138883  0.154837 -0.070032 -0.401689  0.156226   \n",
       "4527 -0.161192  0.219307  0.210620  0.255361 -0.115812 -0.651596  0.238353   \n",
       "4528 -0.072521  0.145689  0.052844  0.181196 -0.081720 -0.507918  0.162997   \n",
       "4529 -0.128059  0.181737  0.148587  0.194918 -0.089350 -0.509447  0.191452   \n",
       "4530 -0.107899  0.177885  0.127513  0.204135 -0.095469 -0.553412  0.197229   \n",
       "\n",
       "            7         8         9   ...        90        91        92  \\\n",
       "0     1.106758 -0.243654  0.316453  ...  0.708754  0.046114  0.278076   \n",
       "1     0.592303 -0.199368 -0.109264  ...  0.210108 -0.020960  0.055184   \n",
       "2     0.599991 -0.208943 -0.122566  ...  0.221674 -0.019684  0.047049   \n",
       "3     0.695668 -0.214826 -0.070413  ...  0.288664 -0.012950  0.080446   \n",
       "4     0.377127 -0.121493 -0.070072  ...  0.130755 -0.011297  0.035960   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4526  0.539385 -0.186336 -0.106543  ...  0.185919 -0.015625  0.049283   \n",
       "4527  0.881353 -0.297987 -0.166253  ...  0.330815 -0.036700  0.091299   \n",
       "4528  0.685408 -0.199122 -0.019366  ...  0.335518  0.006020  0.098136   \n",
       "4529  0.702318 -0.231405 -0.102552  ...  0.293210 -0.019773  0.068850   \n",
       "4530  0.750886 -0.235143 -0.084067  ...  0.316175 -0.015192  0.090131   \n",
       "\n",
       "            93        94        95        96        97        98        99  \n",
       "0    -0.248840  1.710252  0.023575 -0.473314 -0.711494  0.031659  0.250035  \n",
       "1     0.141529  0.620137  0.313458 -0.108117 -0.356073  0.116703  0.082185  \n",
       "2     0.148593  0.641646  0.335417 -0.120881 -0.367762  0.119429  0.084265  \n",
       "3     0.104609  0.798205  0.308668 -0.170043 -0.426662  0.111443  0.114751  \n",
       "4     0.088551  0.397768  0.198146 -0.071384 -0.224143  0.072020  0.052232  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "4526  0.126782  0.559375  0.287423 -0.097047 -0.319445  0.107496  0.073171  \n",
       "4527  0.171524  0.953727  0.444943 -0.180488 -0.544302  0.170642  0.119135  \n",
       "4528  0.082026  0.850471  0.266974 -0.209178 -0.440364  0.095453  0.131223  \n",
       "4529  0.124524  0.795496  0.349724 -0.159801 -0.435084  0.127403  0.108350  \n",
       "4530  0.127776  0.865403  0.341015 -0.190215 -0.469826  0.123497  0.117477  \n",
       "\n",
       "[4531 rows x 100 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(max_depth=10, max_features=0.8)\n",
    "nb_clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shour\\AppData\\Local\\Temp\\ipykernel_9056\\1024668581.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf_clf.fit(x_train, y_train)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, max_features=0.8)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, max_features=0.8)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10, max_features=0.8)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.05      0.09       173\n",
      "           1       0.60      0.88      0.71       608\n",
      "           2       0.56      0.34      0.42       352\n",
      "\n",
      "    accuracy                           0.58      1133\n",
      "   macro avg       0.48      0.42      0.41      1133\n",
      "weighted avg       0.54      0.58      0.53      1133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, rf_clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shour\\anaconda3\\envs\\shourya\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.40      0.33       173\n",
      "           1       0.58      0.81      0.67       608\n",
      "           2       0.30      0.03      0.06       352\n",
      "\n",
      "    accuracy                           0.50      1133\n",
      "   macro avg       0.39      0.41      0.35      1133\n",
      "weighted avg       0.45      0.50      0.43      1133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, nb_clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shourya",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
